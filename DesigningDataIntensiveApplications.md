《数据密集型应用系统设计》

## 软件系统的重要问题

### 可靠性

###可扩展性

### 可维护性


## 数据模型与查询语言

### 数据模型

#### 关系模型

利于表示多对多关系。

#### 文档模型

目标用例是数据来自于自包含文档，且一个文档与其他文档之间的关联很少。

#### 图模型

图数据库的目标用例是所有数据都可能会互相关联。

文档数据库和图数据库，通常不会对存储的数据强加某个模式，这可以使应用程序更容易适应不断变化的需求。但是，应用程序很可能仍然假定数据有一定的结构，只不过是模式是显式（写时强制）还是隐式（读时处理）的问题。


## 数据存储与检索

### 数据库核心：数据结构

#### 哈希索引

	采用磁盘文件（如csv文件）存储key-value对，以内存中的hash map来索引。

写入时，追加到文件末尾。为了避免用尽磁盘空间，将文件分解成一定大小的段，当文件达到一定大小时就关闭它，并将后续写入到新的段文件中。然后可以在段上执行压缩。

每个段都有自己的内存哈希表，将键映射到文件的偏移量。

段文件以追加方式写入而不是原地更新的原因：

- 追加和分段合并主要是顺序写，通常比随机写入快得多。
- 如果段文件是追加的或不可变的，则并发和崩溃恢复要简单得多。
- 合并旧段可以避免随着时间的推移数据文件出现碎片化的问题。

哈希索引的局限性：

- 哈希表必须全部放入内存，如果有大量的键，对内存的消耗很大。
- 区间查询效率不高。

#### SSTables和LSM-Tree

SSTable（Sorted String Table），排序字符串表，要求段文件中key-value对的顺序按键排序，不再按写入顺序。它要求每个键在每个合并的段文件中只能出现一次。

SSTable相比哈希索引的日志段，有以下优点：

- 合并段更加简单高效，即使文件大于可用内存。方法类似于合并排序算法。
- 在文件中查找特定的键时，不再需要在内存中保存所有键的索引。仍然需要一个内存索引来记录某些键的偏移，但它可以是稀疏的。


**构建和维护SSTables：**

- 当写入时，将其添加到内存的平衡树结构中（如红黑树）。内存中的树有时称为**内存表**。
- 当内存表大于某个阈值时，将其作为SSTable文件写入磁盘。当SSTable学磁盘的同时，写入可以继续添加到一个新的内存表实例。
- 为了处理读请求，首先尝试在内存表中查找键，然后查找最新的磁盘段文件，接下来是次新的磁盘段，以此类推，直到找到目标（或为空）。
- 后来进程周期性地执行段文件合并与压缩过程，以合并多个段文件，并丢弃那些已被覆盖或删除的值。

为了避免数据库崩溃导致数据丢失，可以在磁盘上保留单独的日志，将最近的写入追加到该日志。

基于合并和压缩排序文件原理的存储引擎，通常都称为LSM（Log-Structed Merge）存储引擎。

#### B-trees

B-tree将数据库分解成固定大小的块或页，页是哪部读/写的最小单元，这种设计更接近底层硬件，因为磁盘也是以固定大小的块排列。

每个页面都可以使用地址或位置进行标识，这样可以让一个页面引用另一个页面，类似指针，不过是指向磁盘地址而不是内存。可以用这些页面引用来构造一个树状页面。

B-tree底层的基本写操作，是使用新数据覆盖磁盘上的旧页。它假设覆盖不会改变磁盘存储位置，也就是说，当页被覆盖时，对该页的所有引用保持不变。

为了使数据库从崩溃中恢复，常见B-tree的实现需要支持磁盘上的额外的数据结构：预写日志（write-ahead log ， **WAL**）。这是一个仅支持追加的日志，每个B-tree的修改必须先更新WAL然后修改树本身的页。当数据库崩溃后需要恢复时，该日志用于将B-tree恢复到最近一致的状态。


#### 对比B-tree和LSM-tree

根据经验，LSM-tree通常对于写入更快，而B-tree对于读取更快。读取通常在LSM-tree上较慢，因为它们必须在不同的压缩阶段检查多个不同的数据结构和SSTable。

**LSM-tree的优点：**

- B-tree必须至少写两次数据：一次写入WAL，一次写入树的页本身（还可能发生页分裂）。
- 由于反复压缩和SSTable的合并，日志结构索引也会重写数据多次，这称为写放大。
- LSM-tree通常能够成熟比B-tree更高的写入吞吐量。
- LSM-tree可以支持更好地压缩，因此磁盘上的文件比B-tree小很多。

**LSM-tree的缺点：**

- 日志压缩过程有时会干扰正在进行的读写操作。
- 如果数据库希望提供强大的事务语义，这方面B-tree显得更具有吸引力。

#### 其他索引结构

1. 二级索引
2. 在索引中存储值。
	- 聚集索引。将索引行直接存储在索引中。
	- 非聚集索引。仅存储索引中的数据的引用。
	- 覆盖索引。索引中保存一些表的列值。
3. 多列索引。
	- 级联索引。将几个字段组合成一个键。
	- 多维索引。地理空间数据查询。
4. 全文搜索和模糊索引。
	- Lucene
5. 在内存中保存所有内容。
	- Memcached。主要用于缓存。


### 事务处理（OLTP）与分析处理（OLAP）

#### 数据仓库

ETL（Extract-Transform-Load）

#### 星型与雪花型分析模式

星型模式：模式的中心是一个事实表。其他列引用其他表的外键，称为维度表。

雪花模式：其中一个维度细分为子空间。

雪花模式比星型模式更规范化，但是星型模式通常是首选，主要是对于分析人员，星型模式使用起来更简单。


### 列式存储

在大多数OLTP数据库中，存储以面向行的方式布局：来自表的一行的所有值彼此相邻存储。

面向列的存储：将每列中的所有值存储在一起。面向列的存储布局依赖一组列文件，每个文件以相同顺序保存着数据行。

#### 列压缩

面向列的存储非常适合压缩。

#### 列存储中的排序

在列存储中，行的存储顺序可以按照插入顺序保存，也可以基于常见的查询知识来选择要排序表的列，比如以日期作为排序键。

排序的存储便于对数据进行分组或过滤的查询，还可以帮助进一步压缩列。

#### 列存储中的写操作

以LSM-tree方式写入。所有的写入首先进入内存存储区，将其添加到已排序的结构中，接着再准备写入磁盘。

执行查询时，需要检查磁盘上的列数据和内存中最近的写入，并结合这两者。

#### 聚合：数据立方体与物化视图

物化视图：缓存常用的一些计数或聚合函数的结果。

数据立方体/OLAP立方体：由不同维度分组的聚合网格，可以沿着每一行或列应用聚合操作，得到减少一个维度的总和。


## 数据编码与优化

## 数据复制

复制或多副本技术的目的：

- 高可用性
- 连接断开与容错
- 低延迟
- 可扩展性

### 多副本方案

#### 主从复制

所有的客户端写入操作都发送到某一个节点（主节点），由该节点负责将数据更改时间发送到其他副本（从节点）。每个节点都可以接收读请求，但内容可能是过期值。

#### 多主节点复制

系统存在多个主节点，每个都可以接收写请求，客户端将写请求发送到其中一个主节点，由该主节点负责将数据更改事件同步到其他主节点和自己的从节点。

#### 无主节点复制

客户端将写请求发送到多个节点上，读取时从多个节点上并行读取，以此检测和纠正某些过期数据。

无主节点数据库，成为Dynamo风格数据库。Dynamo为亚马逊内部系统。

适用场景：

- 多数据中心。为了容忍整个数据中心级别故障或更接近用户，可以把数据库多副本横跨多个数据中心。可以在每个数据中心都配置主节点，在每个数据中心内，采用常规的主从复制方案；而在数据中心之间，由各个数据中心的主节点来负责同其他数据中心的主节点进行数据的交换、更新。
- 离线客户端操作。应用在与网络断开后还需要继续工作时，在每个设备都有一个充当主节点的本地数据库，然后在所有设备之间采用异步方式同步这些多主节点的副本。
- 协作编辑。

### 一致性模型

一致性模型，帮助应用程序处理复制滞后问题。

#### 写后读一致性

保证用户总能读到自己所提交的最新数据。

#### 单调性

用户在某个时间点读到数据之后，保证此后不会出现比该时间点更早的数据。

#### 前缀一致读

保证数据之间的因果关系。例如，总是以正确的顺序先读取问题，然后看到回答。


## 数据分区

### 分区方法

#### 基于关键字的分区

先对关键字进行排序，每个分区只负责一段包含最小到最大关键字到一段关键字。

- 可以支持高效的区间查询。
- 如果应用程序经常访问与排序一致的某段关键字，会存在热点的风险。
- 当分区太大时，通常将其分裂为两个子区间，从而动态地再平衡分区。

#### 哈希分区

将哈希函数作用于每个关键字，每个分区负责一定范围的哈希值。

- 打破了原关键字的顺序关系，区间查询效率比较低。
- 可以更均匀地分配负载。
- 通常事先创建号足够多（但固定数量）的分区，让每个节点承担多个分区，当添加或删除节点时将某些分区从一个节点迁移到另一个节点，页可以支持动态分区。

### 二级索引分区

#### 基于文档来分区二级索引（本地索引）

二级索引存储在关键字相同的分区中，写入时只需要更新一个分区，缺点是读取二级索引时需要在所有分区上执行scatter/gather。

#### 基于词条来分区二级索引（全局索引）

基于索引的值而进行的独立分区。二级索引中的条目可能包含来自多个分区里的记录。在写入时，不得不更新二级索引的多个分区，引起显著的写放大；但读取时，则可以从单个分区直接快速提取数据。


### 分区再平衡
数据和请求从一个节点迁移到另一个节点。

#### 固定数量的分区

创建远超实际节点数的分区数，然后为每个节点分配多个分区。

#### 动态分区

当分区的数据增大超过一个可配的参数阈值，就拆分为两个分区，每个承担一半的数据量。相反如果数据被大量删除，并且分区缩小到某个阈值一下，则将其与相邻分区进行合并。

#### 按节点比例分区

使分区数与集群节点数成正比关系。每个节点具有固定数量的分区。

当节点数不变时，每个分区的大小与数据集大小保持正比的增长关系；当节点数增加时，分区则会调整变得更小。

## 事务

### 事务提供的安全保证
ACID，原子性、一致性、隔离性、持久性。

### 隔离级别

#### 读-提交

保证：

1. 读数据库时，只能看到已成功提交的数据（防止“脏读”）
2. 写数据库时，只会覆盖已成功提交的数据（防止“脏写”）

通常采用行级锁来防止脏写：当事务想修改某个对象（行或文档）时，必须首先获得该对象的锁；然后一直持有锁直到事务提交或中止。

防止脏读：对每个待更新的对象，都维护其旧值和当前持锁事务将要设置的新值两个版本。在事务提交前，所有其他读操作都读取旧值；仅当事务提交之后，才会切换到读取新值。


### 快照级别隔离与可重复读

读-提交级别有**不可重复读问题**，客户在不同的时间点看到不同值。产生原因是，事务执行期间，有其他事务改变了对象的值，因此两次查询得到的结果不同。

快照隔离是最常用的防范手段，即事务总是在某个时间点的一致性快照中读取数据。通常采用多版本并发控制（MVCC）来实现快照隔离。

在读-提交级别下，对每个不同的查询单独创建一个快照；二快照级别隔离则是使用一个快照来运行整个事务。

当事务读数据库时，通过事务ID可以决定哪些对象可见，哪些不可见。

仅当一下两个条件都成立，则该数据对象对事务可见：

- 事务开始的时刻，创建该对象的事务已经完成了提交。
- 对象没有被标记为删除；即使标记了删除，但删除事务在当前事务开始时还没有完成提交。


### 可串行化的隔离

只有可串行化的隔离可以解决脏读、脏写、不可重复读、更新丢失、写倾斜、幻读的所有问题。

**更新丢失：**两个客户端同时执行读-修改-写入操作序列，出现了其中一个覆盖了另一个读写入，但又没有包含对方最新值的情况，最终导致了部分修改数据发生了丢失。

**写倾斜：**事务首先查询数据，根据返回的结果作出某些决定，然后修改数据库。当事务提交时，支持决定的前提条件已不再成立。

**幻读：**在一个事务中的写入改变了另一个事务查询结果。事务读取了某些符合查询条件的对象，同时另一个客户端执行写入，改变了先前的查询结果。快照隔离只可以避免只读查询时的幻读，但写倾斜情况则需要特殊处理，例如采用区间范围锁（next-key locking）。

实现可串行化执行读三种方法：

1. 严格串行执行事务。
	- 如果每个事务的执行速度非常快，且单个CPU核可以满足事务的吞吐量要求，这是一个非常简单有效的方案。
2. 两阶段加锁。
	- 几十年来实现可串行化的标准方式。
3. 可串行化的快照隔离（SSI）。
	- 一种新的算法，可以边面前面方法的大部分缺点。
	- 它秉持乐观预期的原则，允许多个事务并发执行而不互相阻塞；仅当事务尝试提交时，才检查可能的冲突，如果发现违背了串行化，则某些食物会被中止。
 
 
 Innodb 事务隔离级别：
 
 - Read uncommitted (未提交读) 
 - Read committed (已提交读) 
 - Repeatable read (可重复读) 
 - Serializable (可串行化)


## 一致性与共识

### 最终一致性

大多数多副本的数据库都至少提供了最终一致性。这是一个非常弱的保证，它无法高速我们系统何时会收敛。

### 可线性化

这是最强的一致性模型。基本的想法是，让一个系统看起来好像只有一个数据副本，且所有的操作都是原子的。

一个可线性化的系统中，一旦某个客户端成功提交写请求，所有客户端的读请求一定都能看到刚刚写入的值。

系统容错最常见的方法就是采用复制机制。常见复制方案：

- 主从复制（部分支持可线性化）。如果从主节点或同步更新的从节点上读取，则可以满足线性化。但如果主节点错误，或使用了异步复制，就会违反线性化。
- 共识算法（可线性化）。
- 多主复制（不可线性化）。多主节点复制的系统，同时在多个节点上执行并发写入，并将数据异步复制到其他节点。因此它们可能会发生冲突的写入，需要额外的解决方案。
- 无主复制（可能不可线性化）。无主节点复制的系统（Dynamo风格），其一致性取决于具体的quorum配置，以及如何定义强一致性。

### 因果关系

因果关系对时间进行了某种排序（根据时间发生的原因-结果依赖关系）。

线性化是将所有操作都放在唯一的、全局有序时间线上，而因果性则不同，它为我们提供了一个弱一致性模型：允许存在某些并发事件，所以版本历史是一个包含多个分支与合并的时间线。

因果一致性避免了线性化昂贵的协调开销，且对网络延迟的敏感性要低很多。

### 共识问题

共识意味着就某一项提议，所有节点做出一致的决定，而且决定不可撤销。

事实证明，多个广泛的问题最终都可以归结为共识，并且彼此等价。包括：

- 可线性化的比较-设置寄存器。寄存器需要根据当前值是否等于输入的参数，来自动决定接下来是否应该设置新值。
- 原子事务提交。数据库需要决定是否提交或终止分布式事务。
- 全序广播。消息系统要决定以何种顺序发送消息。
- 锁与租约。当多个客户端争抢锁或租约时，要决定其中哪一个成功。
- 成员/协调服务。对于失败检测器（如超时机制），系统要决定节点的存活状态。
- 唯一性约束。当多个事务在相同的主键上试图并发创建冲突资源时，约束条件要决定哪一个被允许，哪些违反约束因而必须失败。

Zookeeper等工具以一种类似外包方式为应用提供了重要的共识服务、故障检测和成员服务等。

但是，并不是每个系统都需要共识。例如无主复制和多主复制系统通常并不支持全局共识。


