

## 介绍

### Kafka的应用

1. 消息系统
2. 存储系统
3. 流式处理平台


### Kafka架构

一个典型的 Kafka 体系架构包括若干 Producer、若干 Broker、若干 Consumer，以及一个ZooKeeper集群。

其中ZooKeeper是Kafka用来负责集群元数据的管理、控制器的选举等操作的。Producer将消息发送到Broker，Broker负责将收到的消息存储到磁盘中，而Consumer负责从Broker订阅并消费消息。

Kafka中的消息以**主题**为单位进行归类，生产者负责将消息发送到特定的主题（发送到Kafka集群中的每一条消息都要指定一个主题），而消费者负责订阅主题并进行消费。

主题是一个逻辑上的概念，它还可以细分为多个**分区**，一个分区只属于单个主题。每一条消息被发送到broker之前，会根据分区规则选择存储到哪个具体的分区。

#### 多副本

Kafka 为分区引入了**多副本（Replica）**机制，通过增加副本数量可以提升容灾能力。

	同一分区的不同副本中保存的是相同的消息（在同一时刻，副本之间并非完全一样），副本之间是“一主多从”的关系。
	其中leader副本负责处理读写请求，follower副本只负责与leader副本的消息同步。

副本处于不同的broker中，当leader副本出现故障时，从follower副本中重新选举新的leader副本对外提供服务。Kafka通过多副本机制实现了故障的自动转移，当Kafka集群中某个broker失效时仍然能保证服务可用。

生产者和消费者只与leader副本进行交互，而follower副本只负责消息的同步，很多时候follower副本中的消息相对leader副本而言会有一定的滞后。

#### 消费端容灾

Consumer 使用**拉（Pull）模式**从服务端拉取消息，并且保存消费的具体位置，当消费者宕机后恢复上线时可以根据之前保存的消费位置重新拉取需要的消息进行消费，这样就不会造成消息丢失。

#### 副本同步

> 分区中的所有副本统称为**AR（Assigned Replicas）**。

> 所有与leader副本保持一定程度同步的副本（包括leader副本在内）组成**ISR（In-Sync Replicas）**。
ISR集合是AR集合中的一个子集。

消息会先发送到leader副本，然后follower副本才能从leader副本中拉取消息进行同步，同步期间内follower副本相对于leader副本而言会有一定程度的滞后。前面所说的“一定程度的同步”是指可忍受的滞后范围，这个范围可以通过参数进行配置。

> 与leader副本同步滞后过多的副本（不包括leader副本）组成**OSR（Out-of-Sync Replicas）**。
由此可见，AR=ISR+OSR。

在正常情况下，所有的 follower 副本都应该与 leader 副本保持一定程度的同步，即 AR=ISR，OSR集合为空。

**leader副本负责维护和跟踪ISR集合中所有follower副本的滞后状态**，当follower副本落后太多或失效时，leader副本会把它从ISR集合中剔除。如果OSR集合中有follower副本“追上”了leader副本，那么leader副本会把它从OSR集合转移至ISR集合。

**默认情况下，当leader副本发生故障时，只有在ISR集合中的副本才有资格被选举为新的leader**，而在OSR集合中的副本则没有任何机会（不过这个原则也可以通过修改相应的参数配置来改变）。


#### 基于HW和LEO的复制机制


> **Log End Offset（LEO）**，它标识当前日志文件中下一条待写入消息的offset。分区ISR集合中的每个副本都会维护自身的LEO，而ISR集合中最小的LEO即为分区的HW，对消费者而言只能消费HW之前的消息。

> **High Watermark（HW）**，高水位，它标识了一个特定的消息偏移量（offset），<u>ISR中最小的LEO即为HW</u>。消费者只能拉取到HW之前的消息。

![](https://raw.githubusercontent.com/rainsbaby/notebook/master/imgs/kafka/kafka_hw_leo_example.png)

从生产者发出的一条消息首先会被写入分区的leader副本，不过还需要等待ISR集合中的所有follower 副本都同步完之后才能被认为已经提交，之后才会更新分区的 HW，进而消费者可以消费到这条消息。

Kafka 的复制机制既不是完全的同步复制，也不是单纯的异步复制。



## 生产者

KafkaProducer是**线程安全**的，可以在多个线程中共享单个KafkaProducer实例，也可以将KafkaProducer实例进行池化来供其他线程调用。

	发送消息主要有三种模式：发后即忘（fire-and-forget）、同步（sync）及异步（async）。

* 发后即忘，它只管往Kafka中发送消息而并不关心消息是否正确到达。在大多数情况下，这种发送方式没有什么问题，不过在某些时候（比如发生不可重试异常时）会造成消息的丢失。这种发送方式的性能最高，可靠性也最差。
* 同步发送的方式可靠性高，要么消息被发送成功，要么发生异常。如果发生异常，则可以捕获并进行相应的处理，而不会像“发后即忘”的方式直接造成消息的丢失。不过同步发送的方式的性能会差很多，需要阻塞等待一条消息发送完之后才能发送下一条。发送方式为producer.send（record）.get（）。
* 异步发送的方式，一般是在send（）方法里指定一个Callback的回调函数，Kafka在返回响应时调用该函数来实现异步的发送确认。

close（）方法会阻塞等待之前所有的发送请求完成后再关闭 KafkaProducer。

#### 分区器

消息在通过send（）方法发往broker的过程中，有可能需要经过拦截器（Interceptor）、序列化器（Serializer）和分区器（Partitioner）的一系列作用之后才能被真正地发往 broker。

如果消息ProducerRecord中没有指定partition字段，那么就需要依赖分区器，根据key这个字段来计算partition的值。分区器的作用就是为消息分配分区。


#### 生产者拦截器
Kafka一共有两种拦截器：生产者拦截器和消费者拦截器。

生产者拦截器既可以用来在消息发送前做一些准备工作，比如按照某个规则过滤不符合要求的消息、修改消息的内容等，也可以用来在发送回调逻辑前做一些定制化的需求，比如统计类工作。

KafkaProducer 会在消息被应答（Acknowledgement）之前或消息发送失败时调用生产者拦截器的onAcknowledgement（）方法，优先于用户设定的 Callback 之前执行。这个方法运行在Producer的 I/O 线程中，所以这个方法中实现的代码逻辑越简单越好，否则会影响消息的发送速度。

KafkaProducer中不仅可以指定一个拦截器，还可以指定多个拦截器以形成**拦截链**。拦截链会按照interceptor.classes 参数配置的拦截器的顺序来一一执行（配置的时候，各个拦截器之间使用逗号隔开）。

在拦截链中，如果某个拦截器执行失败，那么下一个拦截器会接着从上一个执行成功的拦截器继续执行。

#### 生产者内部架构

Producer端架构如下图：
![](https://raw.githubusercontent.com/rainsbaby/notebook/master/imgs/kafka/kafka_client_architecture.png)

整个生产者客户端由两个线程协调运行，这两个线程分别为主线程和Sender线程（发送线程）。

**ProducerBatch**中可以包含一至多个 ProducerRecord。通俗地说，ProducerRecord 是生产者中创建的消息，而ProducerBatch是指一个消息批次，ProducerRecord会被包含在ProducerBatch中，这样可以使字节的使用更加紧凑，也可以减少网络请求的次数以提升整体的吞吐量。

**InFlightRequests**缓存了已经发出去但还没有收到响应的请求。InFlightRequests还提供了许多管理类的方法，并且通过配置参数还可以限制每个连接（也就是客户端与Node之间的连接）最多缓存的请求数，超过该数值之后就不能再向这个连接发送更多的请求。

InFlightRequests还可以获得leastLoadedNode，即所有Node中负载最小的那一个。选择leastLoadedNode发送请求可以使它能够尽快发出，避免因网络拥塞等异常而影响整体的进度。

**消息发送过程：**

KafkaProducer要将消息追加到指定主题的某个分区所对应的leader副本之前，首先需要知道主题的分区数量，然后经过计算得出（或者直接指定）目标分区，之后KafkaProducer需要知道目标分区的leader副本所在的broker 节点的地址、端口等信息才能建立连接，最终才能将消息发送到 Kafka，在这一过程中所需要的信息都属于元数据信息。

**元数据更新：**
元数据的更新操作是在客户端内部进行的，对客户端的外部使用者不可见。

当需要更新元数据时，会先挑选出leastLoadedNode，然后向这个Node发送MetadataRequest请求来获取具体的元数据信息。这个更新操作是由Sender线程发起的。

#### 配置参数

> acks：指定分区中必须要有多少个副本收到这条消息，之后生产者才会认为这条消息是成功写入的。
> 
> acks=-1（all）时，生产者在消息发送之后，需要等待ISR中的所有副本都成功写入消息之后才能够收到来自服务端的成功响应。
> 
> 在其他配置环境相同的情况下，acks 设置为-1（all）可以达到最强的可靠性。

min.insync.replicas：broker端参数。ISR集合中的最少副本数，默认值是1。只有在acks=all或-1时才有效。

## 消费者

#### 消费组

每一个分区只能被一个消费组中的一个消费者所消费。

消费者与消费组这种模型可以让整体的消费能力具备横向伸缩性，我们可以增加（或减少）消费者的个数来提高（或降低）整体的消费能力。


对于消息中间件而言，一般有两种消息**投递模式：点对点（P2P，Point-to-Point）模式和发布/订阅（Pub/Sub）模式。**点对点模式是基于队列的，消息生产者发送消息到队列，消息消费者从队列中接收消息。发布/订阅模式在消息的一对多广播时采用。

Kafka中，如果所有的消费者都隶属于同一个消费组，那么所有的消息都会被均衡地投递给每一个消费者，即每条消息只会被一个消费者处理，这就相当于点对点模式的应用。如果所有的消费者都隶属于不同的消费组，那么所有的消息都会被广播给所有的消费者，即每条消息会被所有的消费者处理，这就相当于发布/订阅模式的应用。

消费者不仅可以通过KafkaConsumer.subscribe（）方法订阅主题，还可以直接订阅某些主题的特定分区，在KafkaConsumer中还提供了一个assign（）方法来实现这些功能。


**消息消费：**

Kafka中的消费是基于拉模式的。消息的消费一般有两种模式：推模式和拉模式。

Kafka中的消息消费是一个不断轮询的过程，消费者所要做的就是重复地调用poll（）方法，而poll（）方法返回的是所订阅的主题（分区）上的一组消息。

#### 消费位移提交

> 消费者使用offset来表示消费到分区中某个消息所在的位置，称为消费位移。

消费位移的作用：消费者在关闭、崩溃或者在遇到再均衡的时候，可以让接替的消费者能够根据存储的消费位移继续进行消费。

在新消费者客户端中，消费位移存储在Kafka内部的主题**\_\_consumer_offsets**中。这里把将消费位移存储起来（持久化）的动作称为“提交”，消费者在消费完消息之后需要执行消费位移的提交。

在 Kafka 中默认的消费位移的提交方式是**自动提交**，这个由消费者客户端参数enable.auto.commit配置，默认值为 true。

在默认的方式下，消费者每隔5秒会将拉取到的每个分区中最大的消息位移进行提交。自动位移提交的动作是在poll（）方法的逻辑里完成的，在每次真正向服务端发起拉取请求之前会检查是否可以进行位移提交，如果可以，那么就会提交上一次轮询的位移。

自动提交消费位移的方式非常简便，它免去了复杂的位移提交逻辑，让编码更简洁。但随之而来的是**重复消费和消息丢失**的问题。使用本地缓存暂存消息时，就可能出现消息丢失的问题。（主要是消费时间和位移提交时间不是完全一致的，就会导致重复消费或消息丢失）

在Kafka中还提供了**手动位移提交**的方式，这样可以使得开发人员对消费位移的管理控制更加灵活。

手动提交可以细分为同步提交和异步提交。在实际应用中，很少会有每消费一条消息就提交一次消费位移的必要场景。更多时候是按照分区的粒度划分提交位移的界限。

在一般情况下，位移提交失败的情况很少发生，不重试也没有关系，后面的提交也会有成功的。重试会增加代码逻辑的复杂度，不重试会增加重复消费的概率。如果消费者异常退出，那么这个重复消费的问题就很难避免，因为这种情况下无法及时提交消费位移；如果消费者正常退出或发生再均衡的情况，那么可以在退出或再均衡执行之前使用同步提交的方式做最后的把关。

**消费端消息丢失：**

1. 消费端自动提交位移。
2. 消费端手动提交位移。如果是异步提交或批量提交，就可能出现重复消费。



#### 再均衡

再均衡是指分区的所属权从一个消费者转移到另一消费者的行为，它为消费组具备高可用性和伸缩性提供保障，使我们可以既方便又安全地删除消费组内的消费者或往消费组内添加消费者。

再均衡监听器 ConsumerRebalanceListener，用来设定发生再均衡动作前后的一些准备或收尾的动作，如提交消费位移等。


#### 消费者拦截器

ConsumerInterceptor接口，消费者拦截器主要在消费到消息或在提交消费位移时进行一些定制化的操作。

#### 多线程消费

KafkaConsumer是非线程安全的，但是也可以多线程的方式进行消息消费。主要方法：

1. 线程封闭。即为每个线程实例化一个KafkaConsumer，它们属于同一个消费组，每个消费线程消费一个或多个分区。实现简单，但是线程数受限于分区数。
2. 多个消费线程同时消费同一个分区，这个通过 assign（）、seek（）等方法实现，这样可以打破原有的消费线程的个数不能超过分区数的限制，进一步提高了消费的能力。不过这种实现方式对于位移提交和顺序控制的处理就会变得非常复杂，实际应用中使用得极少。
3. 单个线程负责poll消息，然后利用线程池处理消息。相比方法1提高了横向扩展能力，也减少了TCP连接对系统资源的消耗，不过对消息的顺序处理比较困难。


## 主题与分区

### 分区

从Kafka的底层实现来说，主题和分区都是逻辑上的概念，分区可以有一至多个副本，每个副本对应一个日志文件，每个日志文件对应一至多个日志分段（LogSegment），每个日志分段还可以细分为索引文件、日志存储文件和快照文件等。

同一个分区中的多个副本必须分布在不同的broker中，这样才能提供有效的数据冗余。

> 分区使用多副本机制来提升可靠性，但只有leader副本对外提供读写服务，而follower副本只负责在内部进行消息的同步。

如果一个分区的leader副本不可用，那么就意味着整个分区变得不可用，此时就需要Kafka从剩余的follower副本中挑选一个新的leader副本来继续对外提供服务。

从某种程度上说，broker 节点中 leader 副本个数的多少决定了这个节点负载的高低。


#### 优先副本

为了能够有效地治理负载失衡的情况，Kafka引入了优先副本（preferred replica）的概念。

> **优先副本**指在 AR 集合列表中的第一个副本。

Kafka要确保所有主题的优先副本在Kafka集群中均匀分布，这样就保证了所有分区的leader均衡分布。

优先副本的选举，指通过一定的方式促使优先副本选举为leader副本，以此来促进集群的负载均衡，这一行为也可以称为“分区平衡”。

就算集群中的分区分配均衡、leader 分配均衡，也并不能确保整个集群的负载就是均衡的，还需要其他一些硬性的指标来做进一步的衡量

* 自动分区平衡：Kafka 的控制器会启动一个定时任务，这个定时任务会轮询所有的 broker节点，计算每个broker节点的分区不平衡率。如果超过设定的比值，则会自动执行优先副本的选举以求分区平衡。
* 手动分区平衡：一般生产环境中，不建议开启自动分区平衡，因为可能引起客户端的阻塞，或者在流量高峰时期进行自动选举。可以根据指标设置响应的告警，在合适的时候进行手动分区平衡。


#### 分区重分配

当出现以下情况时，需要对分区副本进行合理的分配，对分区进行迁移。

* 集群中节点宕机下线
* 对集群中一个节点进行有计划的下线
* 集群中新增broker。如果不进行重分配，就只有心创建的主题分区才可能被分配到这个节点上，之前的主题分区不会自动分配到新加入的节点中。

分区重分配的基本原理是先通过控制器为每个分区添加新副本（增加副本因子），新的副本将从分区的leader副本那里复制所有的数据。
在复制完成之后，控制器将旧副本从副本清单里移除（恢复为原先的副本因子数）。

减小重分配对集群的影响：1. 降低重分配的粒度，分成多个小批次来进行。2.对副本间的复制流量加以限制，来保证重分配期间整体服务不受太大影响。

#### 修改副本因子（副本数）

修改副本因子的功能也是通过重分配所使用的。

### 如何选择合适的分区数？

1. 利用性能测试工具了解一套硬件的性能指标，之后为其分配合适的应用和负荷。
2. 分区数为1时吞吐量最低，随着分区数的增长，相应的吞吐量也跟着上涨。一旦分区数超过了某个阈值之后，整体的吞吐量是不升反降的。
3. 分区数上限，受可打开的文件描述符个数限制等影响；
4. 有些应用场景会要求主题中的消息都能保证顺序性，这种情况下在创建主题时可以设定分区数为1，通过分区有序性的这一特性来达到主题有序性的目的。
5. 分区数的多少还会影响系统的可用性
6. 建议将分区数设定为集群中broker的倍数，即假定集群中有3个broker节点，可以设定分区数为3、6、9等，至于倍数的选定可以参考预估的吞吐量。


## 日志存储

### 文件目录

不考虑多副本的情况，一个分区对应一个日志（Log）。为了防止 Log 过大，Kafka又引入了**日志分段（LogSegment）**的概念，将Log切分为多个LogSegment。

> Log 在物理上只以文件夹的形式存储，而每个LogSegment 对应于磁盘上的一个日志文件和两个索引文件，以及可能的其他文件。

![](https://raw.githubusercontent.com/rainsbaby/notebook/master/imgs/kafka/kafka_log_architecture.png)

向Log 中追加消息时是顺序写入的，只有最后一个 LogSegment 才能执行写入操作，在此之前所有的 LogSegment 都不能写入数据。

最后一个 LogSegment 称为“**activeSegment**”，即表示当前活跃的日志分段。

随着消息的不断写入，当activeSegment满足一定的条件时，就需要创建新的activeSegment，之后追加的消息将写入新的activeSegment。

为了便于消息的检索，每个LogSegment中的日志文件（以“.log”为文件后缀）都有对应的两个索引文件：**偏移量索引文件**（以“.index”为文件后缀）和**时间戳索引文件**（以“.timeindex”为文件后缀）。每个 LogSegment 都有一个基准偏移量 baseOffset，用来表示当前 LogSegment中第一条消息的offset。

偏移量是一个64位的长整型数，日志文件和两个索引文件都是根据基准偏移量（baseOffset）命名的。

### 日志格式

一条日志中主要包括：

* 每条消息都有一个**offset** 用来标志它在分区中的偏移量，这个offset是逻辑值，而非实际物理偏移值；message size表示消息的大小，这两者在一起被称为日志头部（LOG_OVERHEAD）。LOG_OVERHEAD和RECORD一起用来描述一条消息
* **Record**，其中包括crc32、magic、timestamp、key、value等。timestamp，可以为CreateTime即生产者创建消息时的时间戳，或LogAppendTime。

![](https://raw.githubusercontent.com/rainsbaby/notebook/master/imgs/kafka/kafka_record_content.png)

#### 消息压缩

常见的压缩算法是数据量越大压缩效果越好，一条消息通常不会太大，这就导致压缩效果并不是太好。

而Kafka实现的压缩方式是将**多条消息一起进行压缩**，这样可以保证较好的压缩效果。

在一般情况下，生产者发送的压缩数据在broker中也是保持压缩状态进行存储的，消费者从服务端获取的也是压缩的消息，消费者在处理消息之前才会解压消息，这样保持了端到端的压缩。

#### 变长字段

Kafka还参考了Protocol Buffer而引入了变长整型（Varints）和ZigZag编码。

Varints是使用一个或多个字节来序列化整数的一种方法。数值越小，其占用的字节数就越少。

### 日志索引

两个索引文件，主要用来提高查找消息的效率。

* 偏移量索引文件用来建立消息偏移量（offset）到物理地址之间的映射关系，方便快速定位消息所在的物理文件位置；
* 时间戳索引文件则根据指定的时间戳（timestamp）来查找对应的偏移量信息。

Kafka索引文件以稀疏索引等方式构造消息的索引，它并不保证每个消息在索引文件中都有对应的索引项。

每当写入一定量的消息时，偏移量索引文件和时间戳索引文件分别增加一个偏移量索引项和时间戳索引项。

稀疏索引通过MappedByteBuffer将索引文件映射到内存中，以加快索引的查询速度。

根据偏移量查找方法：首先二分查找。找到不大于目标值的最大索引项所在日志分段，然后到具体的日志分段文件的位置进行跳跃表查找。

根据时间戳索引查找：根据时间戳索引查找对应偏移量，再根据偏移量索引查找对应文件位置，到分段文件中遍历查找。


### 日志清理
两种日志清理策略。

1. 日志删除（Log Retention）：按照一定的保留策略直接删除不符合条件的日志分段。
2. 日志压缩（Log Compaction）：针对每个消息的key进行整合，对于有相同key的不同value值，只保留最后一个版本。

#### 日志删除

在Kafka的日志管理器中会有一个专门的日志删除任务来周期性地检测和删除不符合保留条件的日志分段文件。

删除策略：

1. 基于时间。日志删除任务会检查当前日志文件中是否有保留时间超过设定的阈值（retentionMs）来寻找可删除的日志分段文件集合，过期的判断依据时分段中最大的时间戳。
2. 基于日志大小。日志删除任务检查当前日志的大小是否超过设定的阈值（retentionSize）来寻找可删除的日志分段的文件集合。
3. 基于日志起始偏移量。依据是某日志分段的下一个日志分段的起始偏移量baseOffset是否小于等于logStartOffset。

#### Log Compaction

Log Compaction对于有相同key的不同value值，只保留最后一个版本。

如果应用只关心key对应的最新value值，则可以开启Kafka的日志清理功能，Kafka会定期将相同key的消息进行合并，只保留最新的value值。

![](https://raw.githubusercontent.com/rainsbaby/notebook/master/imgs/kafka/kafka_log_compaction.png)

Log Compaction执行前后，日志分段中的每条消息的偏移量和写入时的偏移量保持一致。

LogCompaction会生成新的日志分段文件，日志分段中每条消息的物理位置会重新按照新文件来组织。

Log Compaction执行过后的偏移量不再是连续的，不过这并不影响日志的查询。


Log Compaction执行过后的日志分段的大小会比原先的日志分段的要小，为了防止出现太多的小文件，Kafka 在实际清理过程中并不对单个的日志分段进行单独清理，而是将日志文件中offset从0至firstUncleanableOffset的所有日志分段进行分组，每个日志分段只属于一组。同一个组的多个日志分段清理过后，只会生成一个新的日志分段。

可能的问题：日志清理时，会使用MD5计算key的hash值，放入SkimpyOffsetMap中。但是MD5会有小概率出现hash值冲突，即两个不同的key但是hash值相同，从而导致其中一个key对应的消息丢失。

Log Compaction会为我们保留key相应的最新value值，那么当我们需要删除一个key怎么办？
使用**墓碑消息**，如果一条消息的key不为null，但其value为null，那么此消息就是墓碑消息。 日志清理线程在发现墓碑消息时会先进行常规的清理，并保留墓碑消息一段时间。



### 磁盘存储

#### 消息追加
Kafka 在设计时采用了文件追加的方式来写入消息，即只能在日志文件的尾部追加新的消息，并且也不允许修改已写入的消息，这种方式属于典型的顺序写盘的操作，所以就算 Kafka使用磁盘作为存储介质，它所能承载的吞吐量也能达到很大。

#### 页缓存

> Kafka 中大量使用了页缓存，这是 Kafka 实现高吞吐的重要因素之一。

页缓存是操作系统实现的一种主要的磁盘缓存，以此用来减少对磁盘 I/O 的操作。具体来说，就是把磁盘中的数据缓存到内存中，把对磁盘的访问变为对内存的访问。

当一个进程准备读取磁盘上的文件内容时，操作系统会先查看待读取的数据所在的页（page）是否在页缓存（pagecache）中，如果存在（命中）则直接返回数据，从而避免了对物理磁盘的 I/O 操作；如果没有命中，则操作系统会向磁盘发起读取请求并将读取的数据页存入页缓存，之后再将数据返回给进程。

同样，如果一个进程需要将数据写入磁盘，那么操作系统也会检测数据对应的页是否在页缓存中，如果不存在，则会先在页缓存中添加相应的页，最后将数据写入对应的页。被修改过后的页也就变成了脏页，操作系统会在合适的时间把脏页中的数据写入磁盘，以保持数据的一致性。

使用文件系统并依赖于页缓存的做法明显要优于维护一个进程内缓存或其他结构，至少我们可以省去了一份进程内部的缓存消耗，同时还可以通过结构紧凑的字节码来替代使用对象的方式以节省更多的空间。

#### 零拷贝

> 零拷贝是指将数据直接从磁盘文件复制到网卡设备中，而不需要经由应用程序之手。

提高了应用程序的性能，减少了内核和用户模式之间的上下文切换。对 Linux操作系统而言，零拷贝技术依赖于底层的 sendfile（）方法实现。对应于 Java 语言，FileChannal.transferTo（）方法的底层实现就是sendfile（）方法。

读取文件，并通过socket发送给用户，文件A经历了4次复制的过程：

* 调用read（）时，文件A中的内容被复制到了内核模式下的Read Buffer中。
* CPU控制将内核模式数据复制到用户模式下。
* 调用write（）时，将用户模式下的内容复制到内核模式下的Socket Buffer中。
* 将内核模式下的Socket Buffer的数据复制到网卡设备中传送。

![](https://raw.githubusercontent.com/rainsbaby/notebook/master/imgs/kafka/kafka_io_readfile.png)

如果采用了零拷贝技术，那么应用程序可以直接请求内核把磁盘中的数据传输给 Socket。

零拷贝技术通过DMA（Direct Memory Access）技术将文件内容复制到内核模式下的Read Buffer中。不过没有数据被复制到 Socket Buffer，相反只有包含数据的位置和长度的信息的文件描述符被加到Socket Buffer中。DMA引擎直接将数据从内核模式中传递到网卡设备（协议引擎）。这里数据只经历了2次复制就从磁盘中传送出去了，并且上下文切换也变成了2次。零拷贝是针对内核模式而言的，数据在内核模式下实现了零拷贝。

![](https://raw.githubusercontent.com/rainsbaby/notebook/master/imgs/kafka/kafka_io_readfile_zerocopy.png)

**总结：Kafka利用日志顺序追加、页缓存和零拷贝技术，保证了数据的高速读写。**




## 服务端

### 协议设计

Kafka自定义了一组基于TCP的二进制协议，只要遵守这组协议的格式，就可以向Kafka发送消息，也可以从Kafka中拉取消息，或者做一些其他的事情，比如提交消费位移等。


### 时间轮

Kafka中存在大量的延时操作，比如延时生产、延时拉取和延时删除等。Kafka并没有使用JDK自带的Timer或DelayQueue来实现延时的功能，而是基于时间轮的概念自定义实现了一个用于延时功能的定时器（SystemTimer）。

DK中Timer和DelayQueue的插入和删除操作的平均时间复杂度为O（nlogn）并不能满足Kafka的高性能要求，而基于时间轮可以将插入和删除操作的时间复杂度都降为O（1）。时间轮的应用并非Kafka独有，其应用场景还有很多，在Netty、Akka、Quartz、ZooKeeper等组件中都存在时间轮的踪影。

Kafka中的时间轮（TimingWheel）是一个存储定时任务的环形队列，底层采用数组实现，数组中的每个元素可以存放一个定时任务列表（TimerTaskList）。TimerTaskList是一个环形的双向链表，链表中的每一项表示的都是定时任务项（TimerTaskEntry），其中封装了真正的定时任务（TimerTask）。

![](https://raw.githubusercontent.com/rainsbaby/notebook/master/imgs/kafka/kafka_server_timingwheel.png)


Kafka有层级时间轮，当任务的到期时间超过了当前时间轮所表示的时间范围时，就会尝试添加到上层时间轮中。
![](https://raw.githubusercontent.com/rainsbaby/notebook/master/imgs/kafka/kafka_server_timingwheel_levels.png)

Kafka 中的 TimingWheel 专门用来执行插入和删除 TimerTaskEntry的操作，而 DelayQueue 专门负责时间推进的任务。


### 延时操作

在将消息写入 leader 副本的本地日志文件之后，Kafka会创建一个延时的生产操作（DelayedProduce），用来处理消息正常写入所有副本或超时的情况，以返回相应的响应结果给客户端。

延时操作创建之后会被加入延时操作管理器（DelayedOperationPurgatory）来做专门的处理。

每个延时操作管理器都会配备一个定时器（SystemTimer）来做超时管理，定时器的底层就是采用时间轮（TimingWheel）实现的。

### 控制器

在 Kafka 集群中会有一个或多个 broker，其中有一个 broker 会被选举为控制器（KafkaController），它负责管理整个集群中所有分区和副本的状态。当某个分区的leader副本出现故障时，由控制器负责为该分区选举新的leader副本。当检测到某个分区的ISR集合发生变化时，由控制器负责通知所有broker更新其元数据信息。

Kafka中的控制器选举工作依赖于ZooKeeper。

具备控制器身份的broker比其他普通的broker多一份职责:

* 监听分区相关的变化
* 监听主题相关的变化
* 监听broker相关的变化。
* 从ZooKeeper中读取获取当前所有与主题、分区及broker有关的信息并进行相应的管理。
* 启动并管理分区状态机和副本状态机
* 更新集群的元数据信息
* 如果参数 auto.leader.rebalance.enable 设置为 true，则还会开启一个名为“auto-leader-rebalance-task”的定时任务来负责维护分区的优先副本的均衡。

控制器在选举成功之后会读取 ZooKeeper 中各个节点的数据来初始化上下文信息（ControllerContext），并且需要管理这些上下文信息。

#### 分区Leader的选举

分区leader副本的选举由控制器负责具体实施。当创建分区（创建主题或增加分区都有创建分区的动作）或分区上线（比如分区中原先的leader副本下线，此时分区需要选举一个新的leader 上线来对外提供服务）的时候都需要执行 leader 的选举动作。

创建分区、分区上线/下线、分区重分配、优先副本选举时，会有不同的选举策略。


## 客户端

### 分区分配策略

消费者与订阅主题间的分区分配策略：

1. RangeAssignor分配策略。按照消费者总数和分区总数进行整除运算来获得一个跨度，然后将分区按照跨度进行平均分配，以保证分区尽可能均匀地分配给所有的消费者。
	
	如果消费组内的消费者订阅的消息是不同的，就会导致分配不均匀，某些消费者压力更大。
2. RoundRobinAssignor。将消费组内所有消费者及消费者订阅的所有主题的分区按照字典序排序，然后通过轮询方式逐个将分区依次分配给每个消费者。
	
	如果同一个消费组内的消费者订阅的信息是不相同的，那么在执行分区分配的时候就不是完全的轮询分配，有可能导致分区分配得不均匀。
3. StickyAssignor。它主要有两个目的：（1）分区的分配要尽可能均匀。（2）分区的分配尽可能与上次分配的保持相同。实现比较复杂，能够比RoundRobinAssignor分配的更均匀。


### 消费者协调器（ConsumerCoordinator）和组协调器（GroupCoordinator）

Kafka将全部消费组分成多个子集，每个消费组的子集在服务端对应一个GroupCoordinator对其进行管理，**GroupCoordinator**是Kafka服务端中用于管理消费组的组件。而消费者客户端中的**ConsumerCoordinator**组件负责与GroupCoordinator进行交互。

ConsumerCoordinator与GroupCoordinator之间最重要的职责就是负责执行消费者再均衡的操作，包括分区分配的工作也是在再均衡期间完成的。


有新消费者加入消费组时，再均衡过程：

#### 1. FIND_COORDINATOR

消费者需要确定它所属的消费组对应的GroupCoordinator所在的broker，并创建与该broker相互通信的网络连接。

#### 2. JOIN_GROUP

消费者向GroupCoordinator发送JoinGroupRequest请求，并处理响应。

* 选举消费组的leader。GroupCoordinator为消费组内的消费者选举出一个leader，可认为是随机选择。
* 选举分区分配策略。每个消费者都可以设置自己的分区分配策略，对消费组而言需要从各个消费者呈报上来的各个分配策略中选举一个彼此都“信服”的策略来进行整体上的分区分配。

#### 3. SYNC_GROUP

leader 消费者根据在第二阶段中选举出来的分区分配策略来实施具体的分区分配，在此之后需要将分配的方案同步给各个消费者，此时leader消费者并不是直接和其余的普通消费者同步分配方案，而是通过 GroupCoordinator 这个“中间人”来负责转发同步分配方案的。

在同步阶段，各个消费者会向GroupCoordinator发送SyncGroupRequest请求来同步分配方案。

当消费者收到所属的分配方案之后会调用PartitionAssignor中的onAssignment（）方法。随后再调用ConsumerRebalanceListener中的OnPartitionAssigned（）方法。之后开启心跳任务，消费者定期向服务端的GroupCoordinator发送HeartbeatRequest来确定彼此在线。

#### 4. HEARTBEAT

消费者通过向 GroupCoordinator 发送心跳来维持它们与消费组的从属关系，以及它们对分区的所有权关系。

如果消费者一定时间内没有发送心跳，GroupCoordinator就认为这个消费者已经死亡，就会触发一次再均衡行为。


### 消费位移提交

消费者位移提交的内容最终会保存到Kafka的内部主题__consumer_offsets中。

一般情况下，当集群中第一次有消费者消费消息时会自动创建主题__consumer_offsets。

### 事务

当生产者向 Kafka 发送消息时，一旦消息被成功提交到日志文件，由于多副本机制的存在，这条消息就不会丢失。Kafka 提供的消息传输保障为 at least once。

对消费者而言，消费者处理消息和提交消费位移的顺序在很大程度上决定了消费者提供哪一种消息传输保障。如果先消费后提交消费位移，就可能出现重复消费；如果先提交消费位移后消费，即可能出现消息丢失。

#### 幂等

Kafka引入序列号来实现幂等，但是只能保证单个生产者中单分区的幂等。

#### 事务

幂等性并不能跨多个分区运作，而事务可以弥补这个缺陷。事务可以保证对多个分区写入操作的原子性。

为了实现事务的功能，Kafka引入了事务协调器（TransactionCoordinator）来负责处理事务。每一个生产者都会被指派一个特定的TransactionCoordinator，所有的事务逻辑包括分派 PID 等都是由 TransactionCoordinator 来负责实施的。TransactionCoordinator 会将事务状态持久化到内部主题__transaction_state 中。


## 可靠性探究

* Kafka 多副本之间如何进行数据同步，尤其是在发生异常时候的处理机制又是什么？
* 多副本间的数据一致性如何解决，基于的一致性协议又是什么？
* 如何确保 Kafka 的可靠性？
* Kafka 中的可靠性和可用性之间的关系又如何？


### 副本

* 数据副本：在不同的节点上持久化同一份数据，当某一个节点上存储的数据丢失时，可以从副本上读取该数据，这是解决分布式系统数据丢失问题最有效的手段。
* 服务副本，指多个节点提供同样的服务，每个节点都有能力接收来自外部的请求并进行相应的处理。

副本同步：从生产者发出的一条消息首先会被写入分区的leader副本，不过还需要等待ISR集合中的所有follower 副本都同步完之后才能被认为已经提交，之后才会更新分区的 HW，进而消费者可以消费到这条消息。

#### 失效副本

在ISR集合之外，也就是处于同步失效或功能失效（比如副本处于非存活状态）的副本统称为失效副本，失效副本对应的分区也就称为同步失效分区，即under-replicated分区。

当ISR集合中的一个follower副本滞后leader副本的时间超过此参数指定的值时则判定为同步失败，需要将此follower副本剔除出ISR集合。

Kafka 在启动的时候会开启两个与 ISR 相关的定时任务，名称分别为“isr-expiration”和“isr-change-propagation”。isr-expiration任务会周期性地检测每个分区是否需要**缩减其ISR**集合。

随着follower副本不断与leader副本进行消息同步，follower副本的LEO也会逐渐后移，并最终追赶上leader副本，此时该follower副本就有资格**进入ISR集合**。追赶上leader副本的判定准则是此副本的LEO是否不小于leader副本的HW。

#### 消息追加过程

* 生产者客户端发送消息至leader副本（副本1）中。
* 消息被追加到leader副本的本地日志，并且会更新日志的偏移量。
* follower副本（副本2和副本3）向leader副本请求同步数据。
* leader副本所在的服务器读取本地日志，并更新对应拉取的follower副本的信息。
* leader副本所在的服务器将拉取结果返回给follower副本。
* follower副本收到leader副本返回的拉取结果，将消息追加到本地日志中，并更新日志的偏移量信息。

#### 定时备份

Kafka 中会有一个定时任务负责将所有分区的 **LEO** 刷写到恢复点文件 recovery-point-offset-checkpoint 中。

还有一个定时任务负责将所有分区的**HW**刷写到复制点文件replication-offset-checkpoint中。

Kafka 也有一个定时任务来负责将所有分区的 **logStartOffset**（日志文件的起始偏移量）书写到起始点文件log-start-offset-checkpoint。

#### 为什么不支持读写分离？

在Kafka中，生产者写入消息、消费者读取消息的操作都是与leader副本进行交互的，从而实现的是一种**主写主读的生产消费模型**。

主写从读的缺点：1.数据一致性问题； 2.延时问题。主写从读可以均摊一定的负载，但是不能做到完全的负载均衡，比如写多读少的情况。

Kafka利用如下的架构，可以在主写主读的架构上实现很大程度上的负载均衡。将分区均衡地分配到不同的broker上，从而每个broker上的读写负载都是一样的。

![](https://raw.githubusercontent.com/rainsbaby/notebook/master/imgs/kafka/kafka_producer_consumer_model.png)

另外，在主题创建时尽可能使分区均衡分配。同时，Kafka 提供了优先副本的选举来达到 leader 副本的均衡，与此同时，也可以配合相应的监控、告警和运维平台来实现均衡的优化。

Kafka 只支持主写主读有几个优点：可以简化代码的实现逻辑，减少出错的可能；将负载粒度细化均摊，与主写从读相比，不仅负载效能更好，而且对用户可控；没有延时的影响；在副本稳定的情况下，不会出现数据不一致的情况。


### 日志同步机制

follower的同步状态可能落后leader很多，甚至还可能处于宕机状态，所以必须确保选择具有最新日志消息的follower作为新的leader。

> 日志同步机制的一个基本原则就是：如果告知客户端已经成功提交了某条消息，那么即使 leader宕机，也要保证新选举出来的leader中能够包含这条消息。

解决方式：

1. 少数服从多数

	Zab、Raft和Viewstamped Replication等一致性算法。

	在生产环境下为了保证较高的容错率，必须要有大量的副本，而大量的副本又会在大数据量下导致性能的急剧下降。这也就是“少数服从多数”的这种Quorum模型常被用作共享集群配置（比如ZooKeeper），而很少用于主流的数据存储中的原因。
	
2. Kafka日志同步机制，类似PacificA算法。

	在Kafka中动态维护着一个ISR集合，处于ISR集合内的节点保持与leader相同的高水位（HW），只有位列其中的副本才有资格被选为新的 leader。
	
	写入消息时只有等到所有 ISR 集合中的副本都确认收到之后才能被认为已经提交。位于 ISR 中的任何副本节点都有资格成为 leader，选举过程简单、开销低，这也是Kafka选用此模型的重要因素。Kafka中包含大量的分区，leader副本的均衡保障了整体负载的均衡，所以这一因素也极大地影响Kafka的性能指标。
	
	在需要相同确认信息数的情况下，采用ISR的方式所需要的副本总数变少，复制带来的集群开销也就更低，“少数服从多数”的优势在于它可以绕开最慢副本的确认信息，降低提交的延迟，而对Kafka而言，这种能力可以交由客户端自己去选择。

一般的同步策略依赖于稳定的存储系统来做数据恢复。而Kafka 不需要宕机节点必须从本地数据日志中进行恢复，Kafka 的同步方式允许宕机副本重新加入ISR集合，但在进入ISR之前必须保证自己能够重新同步完leader中的所有数据，即从leader同步数据然后加入ISR集合。

### 可靠性

如何保证高可靠性？

1. 一般设置副本数为3，即可满足绝大多数场景对可靠性的要求，而对可靠性要求更高的场景下，可以适当增大这个数值，比如国内部分银行在使用 Kafka 时会设置副本数为 5。
2. 生产者客户端参数 acks，相比于0和1，acks=-1/all 可以最大程度地提高消息的可靠性。
3. 对于生产者，如果使用发后即忘的模式，不管消息有没有被成功写入，生产者都不会收到通知，那么即使消息写入失败也无从得知，因此发后即忘的模式不适合高可靠性要求的场景。如果要提升可靠性，那么生产者可以采用同步或异步的模式，在出现异常情况时可以及时获得通知，以便可以做相应的补救措施，比如选择重试发送（可能会引起消息重复）。
4. 发送客户端内部的重试机制，可解决网络故障导致的异常，不过可能影响消息的顺序性。
5. min.insync.replicas参数（默认值为1）配合acks=-1来使用，这个参数指定了ISR集合中最小的副本数。在副本数为3时，将这个参数设置为2.
6. 消费端，需要将enable.auto.commit 参数设置为 false 来执行手动位移提交。在执行手动位移提交的时候也要遵循一个原则：如果消息没有被成功消费，那么就不能提交所对应的消费位移。对于高可靠要求的应用来说，宁愿重复消费也不应该因为消费异常而导致消息丢失。
7. 对于消费端，Kafka 还提供了一个可以兜底的功能，即回溯消费。


## Kafka应用

1. 命令行工具
2. Kafka Connect
3. Kafka Mirror Maker
4. Kafka Streams

### 过期时间TTL

将消息的TTL的设定值以键值对的形式保存在消息的 headers 字段中，这样消费者消费到这条消息的时候可以在拦截器中根据 headers 字段设定的超时时间来判断此条消息是否超时，而不是根据原先固定的EXPIRE_INTERVAL值来判断。

### 延时队列

> “延时消息”是指消息被发送以后，并不想让消费者立刻获取，而是等待特定的时间后，消费者才能获取这个消息进行消费，延时队列一般也被称为“延迟队列”。

场景：下单后30分钟内要支付订单；订单完成1小时后通知用户评价。

实现方式：

1. 在发送延时消息的时候并不是先投递到要发送的真实主题（real_topic）中，而是先投递到一些 **Kafka 内部的主题**（delay_topic）中，这些内部主题对用户不可见，然后通过一个自定义的服务拉取这些内部主题中的消息，并将满足条件的消息再投递到要发送的真实的主题中，消费者所订阅的还是真实的主题。

	内部主题按照不同的延时等级来划分，比如设定5s、10s、30s、1min、2min、5min、10min、20min、30min、45min、1hour、2hour这些按延时时间递增的延时等级。延时的消息按照延时时间投递到不同等级的主题中，投递到同一主题中的消息的延时时间会被强转为与此主题延时等级一致的延时时间，这样延时误差控制在两个延时等级的时间差范围之内。

	这种方案有一定的延时误差，无法做到秒级别的精确延时。适合对延时精度要求不高的场景。
	
![](https://raw.githubusercontent.com/rainsbaby/notebook/master/imgs/kafka/kafka_delay_queue_delaytopic.png)	
2. 在Kafka服务中增加一个**前置缓存**，生产者还是正常将消息发往Kafka中，Kafka在判定消息是延时消息时（可以增加一个自定义协议，与发送普通消息的PRODUCE协议分开，比如DELAY_PRODUCE，作为发送延时消息的专用协议）就将消息封装成延时操作并暂存至缓存中，待延时操作触发时就会将消息发送到真实的主题中。为了保证消息可靠性，要引入缓存多副本的机制。
	
	可以实现高精度的延时，但是要修改kafka内核代码。
	
3. 自己开发一个精度较高的延时模块。基于时间轮的概念，实现一个基于文件的单层时间轮。时间轮中每个时间格代表一个延时时间，并且每个时间格也对应一个文件。

并不需要维持所有文件的文件句柄，只需要加载距离时间轮表盘指针（currentTime）相近位置的部分文件即可，其余都可以用类似“懒加载”的机制来维持：若与时间格对应的文件不存在则可以新建，若与时间格对应的文件未加载则可以重新加载，整体上造成的时延相比于延时等级方案而言微乎其微。

随着表盘指针的转动，其相邻的文件也会变得不同，整体上在内存中只需要维持少量的文件句柄就可以让系统运转起来。

可靠性保证：消息写入多个副本，即多个单层时间轮。

![](https://raw.githubusercontent.com/rainsbaby/notebook/master/imgs/kafka/kafka_delay_queue_timewheeling.png)


### 死信队列和重试队列

> 由于某些原因消息无法被正确地投递，为了确保消息不会被无故地丢弃，一般将其置于一个特殊角色的队列，这个队列一般称为**死信队列**。

后续分析程序可以通过消费这个死信队列中的内容来分析当时遇到的异常情况，进而可以改善和优化系统。

如果消费者在消费时发生了异常，那么就不会对这一次消费进行确认，进而发生回滚消息的操作之后，消息始终会放在队列的顶部，然后不断被处理和回滚，导致队列陷入死循环。为了解决这个问题，可以为每个队列设置一个**回退队列**。

**重试队列**可以看作一种回退队列，具体指消费端消费消息失败时，为了防止消息无故丢失而重新将消息回滚到broker中。与回退队列不同的是，重试队列一般分成多个重试等级，每个重试等级一般也会设置重新投递延时，重试次数越多投递延时就越大。

死信队列、回退队列和重试队列，都是为异常处理提供的一种保护机制。

### 消息路由

在消息中间件 RabbitMQ 中使用路由键RoutingKey来进行消息路由。RabbitMQ中的生产者将消息发送到交换器Exchange中，然后由交换器根据指定的路由键来将消息路由到一个或多个队列中，消费者消费的是队列中的消息。从整体上而言，RabbitMQ通过路由键将原本发往一个地方的消息做了区分，然后让不同的消息者消费到自己要关注的消息。

Kafka默认按照主题进行路由，也就是说，消息发往主题之后会被订阅的消费者全盘接收，没有类似消息路由的功能来将消息进行二级路由。如果需要消息路由，可以通过细粒度化切分主题来实现。

如何给Kafka添加消息路由能力：

我们首先需要在这个整体架构中做一层关系映射。将Kafka中的消费组与RabbitMQ中的队列做了一层映射，可以根据特定的标识来将消息投递到对应的消费组中，消费组根据消息特定的标识来获取消息，其余的都可以被过滤。

具体的实现方式可以在消息的 headers 字段中加入一个键为“routingkey”、值为特定业务标识的Header，然后在消费端中使用拦截器挑选出特定业务标识的消息。

### 消息轨迹

> 消息轨迹指的是一条消息从生产者发出，经由broker存储，再到消费者消费的整个过程中，各个相关节点的状态、时间、地点等数据汇聚而成的完整链路信息。

生产者、broker、消费者这3个角色在处理消息的过程中都会在链路中增加相应的信息，将这些信息汇聚、处理之后就可以查询任意消息的状态，进而为生产环境中的故障排除提供强有力的数据支持。

我们可以将轨迹信息保存到Kafka的某个主题中。

### 消息审计

> 消息审计是指在消息生产、存储和消费的整个过程之间对消息个数及延迟的审计，以此来检测是否有数据丢失、是否有数据重复、端到端的延迟又是多少等内容。

### 消息中间件选型

> 目前开源的消息中间件有很多，比如ActiveMQ、RabbitMQ、Kafka、RocketMQ、ZeroMQ等。

1. Apache ActiveMQ，Java编写，市场份额不高。
2. RabbitMQ是采用Erlang语言实现的AMQP协议的消息中间件，最初起源于金融系统，也主要用于金融行业，用于在分布式系统中存储和转发消息。RabbitMQ发展到今天，被越来越多的人认可，在可靠性、可用性、扩展性、功能丰富等方面有卓越表现。
3. RocketMQ是阿里开源的消息中间件，目前已经捐献给Apache基金会，它由Java语言开发，具备高吞吐量、高可用性、适合大规模分布式系统应用等特点。
4. ZeroMQ号称史上最快的消息队列，基于C/C++开发。ZeroMQ是一个消息处理队列库，可在多线程、多内核和主机之间弹性伸缩。
5. Kafka主要用于日志、大数据行业等。

技术选型考虑维度：

1. 功能维度
	
	* 优先级队列
	* 延时队列
	* 重试队列
	* 死信队列
	* 消费模式（推模式和拉模式）。推拉模式的时候指的是 Comsumer 和 Broker 之间的交互。RocketMQ 和 Kafka 都选择了拉模式，RabbitMQ支持推拉两种模式。
		
		默认的认为 Producer 与 Broker 之间就是推的方式，即 Producer 将消息推送给 Broker，而不是 Broker 主动去拉取消息。
		
		推模式，推送速率难以适应消费速率，可能压垮消费端。适合消息量不大、消费能力强、实时性要求高的场景。
		
		拉模式，消费端根据自身情况发起拉取消息请求，可能导致消息延迟。
		
	* 广播消费（点对点模式和发布/订阅模式）。

	点对点的模式，消息被消费以后，队列中不会再存储消息，所以消息消费者不可能消费已经被消费的消息。虽然队列可以支持多个消费者，但是一条消息只会被一个消费者消费。
	
	发布/订阅模式定义了如何向一个内容节点发布和订阅消息，这个内容节点称为主题，主题可以认为是消息传递的中介，消息发布者将消息发布到某个主题，而消息订阅者从主题中订阅消息。主题使得消息的订阅者与消息的发布者互相保持独立，不需要进行接触即可保证消息的传递，发布/订阅模式在消息的一对多广播时采用。
	
	RabbitMQ 是一种典型的点对点模式，而Kafka是一种典型的发布/订阅模式。但是在RabbitMQ中可以通过设置交换器类型来实现发布/订阅模式，从而实现广播消费的效果。
	
	* 回溯消费。消息在消费完成之后，还能消费之前被消费的消息。Kafka支持回溯消费。
	* 消息堆积+持久化。消息中间件必备能力。
	
	消息堆积分内存式堆积和磁盘式堆积。
	
	RabbitMQ是典型的内存式堆积，但这并非绝对，在某些条件触发后会有换页动作来将内存中的消息换页到磁盘（换页动作会影响吞吐），或者直接使用惰性队列来将消息直接持久化至磁盘中。
	
	Kafka 是一种典型的磁盘式堆积，所有的消息都存储在磁盘中。
	
	* 消息轨迹
	* 消息审计
	* 多租户
	* 多协议支持。一般消息层面的协议有AMQP、MQTT、STOMP、XMPP等。
	* 跨语言支持
	* 流量控制
	* 消息顺序性
	* 安全机制
	* 消息幂等性
	* 事务性消息
	
2. 性能维度。消息中间件的性能一般是指其吞吐量，虽然从功能维度上来说，RabbitMQ的优势要大于Kafka，但是Kafka的吞吐量要比RabbitMQ高出1至2个数量级，一般RabbitMQ的单机QPS在万级别之内，而Kafka的单机QPS可以维持在十万级别，甚至可以达到百万级。

时延是性能维度的另一个重要指标。消息中间件能够解耦系统，一个时延较低的消息中间件可以让上游生产者发送消息之后迅速返回，也可以让消费者更加快速地获取消息，在没有堆积的情况下可以让整体上下游的应用之间的级联动作更高效。

3. 可靠性和可用性。
4. 运维管理。
5. 社区力度及生态发展。性能优化的空间没有功能扩展的空间大。然而对于长期发展而言，生态又比性能及功能都要重要。


目前，在金融支付领域使用 RabbitMQ 居多，而在日志处理、大数据等方面 Kafka 使用居多。


## Kafka3

Kafka3中完善了KRaft，以替代Zookeeper。不过目前还不推荐在生产中使用。


## Kafka 核心问题

1. Consumer是推模式or拉模式？
2. 在哪些场景下选择使用Kafka？
3. Kafka的设计架构
4. Kafka 分区的目的？
5. Kafka 如何做到消息的有序性？
6. Kafka 的高可靠性是怎么实现的？
7. Kafka 数据一致性原理
8. ISR、OSR、AR 是什么？
9. LEO、HW、LSO、LW等分别代表什么
10. Kafka 在什么情况下会出现消息丢失？
11. 怎么尽可能保证 Kafka 的可靠性
12. 消费者和消费者组有什么关系？
13. Kafka 的每个分区只能被一个消费者线程，如何做到多个线程同时消费一个分区？
14. 数据传输的事务有几种？
15. Kafka 消费者是否可以消费指定分区消息？
16. Kafka 高效文件存储设计特点
17. Kafka创建Topic时如何将分区放置到不同的Broker中
18. Kafka 的再均衡
19. Kafka 分区分配策略
20. Kafka Producer 是如何动态感知主题分区数变化的？
21. Kafka 是如何实现高吞吐率的？（顺序读写；页缓存；零拷贝；文件分段；批量发送；数据压缩。
22. 如何为Kafka集群选择合适的Topics/Partitions数量
23. Kafka 事务
24. Kafka 幂等
25. Kafka 的缺点？
26. Kafka 分区数可以增加或减少吗？为什么？
27. Zookeeper对Kafka的作用



## 参考

《深入理解Kafka：核心设计与实践原理》