Kafka

## 介绍

### Kafka的应用

1. 消息系统
2. 存储系统
3. 流式处理平台


### Kafka架构

一个典型的 Kafka 体系架构包括若干 Producer、若干 Broker、若干 Consumer，以及一个ZooKeeper集群。

其中ZooKeeper是Kafka用来负责集群元数据的管理、控制器的选举等操作的。Producer将消息发送到Broker，Broker负责将收到的消息存储到磁盘中，而Consumer负责从Broker订阅并消费消息。

Kafka中的消息以**主题**为单位进行归类，生产者负责将消息发送到特定的主题（发送到Kafka集群中的每一条消息都要指定一个主题），而消费者负责订阅主题并进行消费。

主题是一个逻辑上的概念，它还可以细分为多个**分区**，一个分区只属于单个主题。每一条消息被发送到broker之前，会根据分区规则选择存储到哪个具体的分区。

#### 多副本

Kafka 为分区引入了**多副本（Replica）**机制，通过增加副本数量可以提升容灾能力。

同一分区的不同副本中保存的是相同的消息（在同一时刻，副本之间并非完全一样），副本之间是“一主多从”的关系，其中leader副本负责处理读写请求，follower副本只负责与leader副本的消息同步。

副本处于不同的broker中，当leader副本出现故障时，从follower副本中重新选举新的leader副本对外提供服务。Kafka通过多副本机制实现了故障的自动转移，当Kafka集群中某个broker失效时仍然能保证服务可用。

生产者和消费者只与leader副本进行交互，而follower副本只负责消息的同步，很多时候follower副本中的消息相对leader副本而言会有一定的滞后。

#### 消费端容灾

Consumer 使用拉（Pull）模式从服务端拉取消息，并且保存消费的具体位置，当消费者宕机后恢复上线时可以根据之前保存的消费位置重新拉取需要的消息进行消费，这样就不会造成消息丢失。

#### 副本同步

分区中的所有副本统称为**AR（Assigned Replicas）**。

所有与leader副本保持一定程度同步的副本（包括leader副本在内）组成**ISR（In-Sync Replicas）**，ISR集合是AR集合中的一个子集。消息会先发送到leader副本，然后follower副本才能从leader副本中拉取消息进行同步，同步期间内follower副本相对于leader副本而言会有一定程度的滞后。前面所说的“一定程度的同步”是指可忍受的滞后范围，这个范围可以通过参数进行配置。

与leader副本同步滞后过多的副本（不包括leader副本）组成**OSR（Out-of-Sync Replicas）**，由此可见，AR=ISR+OSR。

在正常情况下，所有的 follower 副本都应该与 leader 副本保持一定程度的同步，即 AR=ISR，OSR集合为空。

leader副本负责维护和跟踪ISR集合中所有follower副本的滞后状态，当follower副本落后太多或失效时，leader副本会把它从ISR集合中剔除。如果OSR集合中有follower副本“追上”了leader副本，那么leader副本会把它从OSR集合转移至ISR集合。

默认情况下，当leader副本发生故障时，只有在ISR集合中的副本才有资格被选举为新的leader，而在OSR集合中的副本则没有任何机会（不过这个原则也可以通过修改相应的参数配置来改变）。


#### 基于HW和LEO的复制机制

**High Watermark（HW）**，高水位，它标识了一个特定的消息偏移量（offset），消费者只能拉取到这个offset之前的消息。

**Log End Offset（LEO）**，它标识当前日志文件中下一条待写入消息的offset。分区ISR集合中的每个副本都会维护自身的LEO，而ISR集合中最小的LEO即为分区的HW，对消费者而言只能消费HW之前的消息。

Kafka 的复制机制既不是完全的同步复制，也不是单纯的异步复制。

![](https://raw.githubusercontent.com/rainsbaby/notebook/master/imgs/kafka/kafka_hw_leo_example.png)


## 生产者

KafkaProducer是**线程安全**的，可以在多个线程中共享单个KafkaProducer实例，也可以将KafkaProducer实例进行池化来供其他线程调用。

发送消息主要有三种模式：发后即忘（fire-and-forget）、同步（sync）及异步（async）。

* 发后即忘，它只管往Kafka中发送消息而并不关心消息是否正确到达。在大多数情况下，这种发送方式没有什么问题，不过在某些时候（比如发生不可重试异常时）会造成消息的丢失。这种发送方式的性能最高，可靠性也最差。
* 同步发送的方式可靠性高，要么消息被发送成功，要么发生异常。如果发生异常，则可以捕获并进行相应的处理，而不会像“发后即忘”的方式直接造成消息的丢失。不过同步发送的方式的性能会差很多，需要阻塞等待一条消息发送完之后才能发送下一条。发送方式为producer.send（record）.get（）。
* 异步发送的方式，一般是在send（）方法里指定一个Callback的回调函数，Kafka在返回响应时调用该函数来实现异步的发送确认。

close（）方法会阻塞等待之前所有的发送请求完成后再关闭 KafkaProducer。

#### 分区器

消息在通过send（）方法发往broker的过程中，有可能需要经过拦截器（Interceptor）、序列化器（Serializer）和分区器（Partitioner）的一系列作用之后才能被真正地发往 broker。

如果消息ProducerRecord中没有指定partition字段，那么就需要依赖分区器，根据key这个字段来计算partition的值。分区器的作用就是为消息分配分区。


#### 生产者拦截器
Kafka一共有两种拦截器：生产者拦截器和消费者拦截器。

生产者拦截器既可以用来在消息发送前做一些准备工作，比如按照某个规则过滤不符合要求的消息、修改消息的内容等，也可以用来在发送回调逻辑前做一些定制化的需求，比如统计类工作。

KafkaProducer 会在消息被应答（Acknowledgement）之前或消息发送失败时调用生产者拦截器的onAcknowledgement（）方法，优先于用户设定的 Callback 之前执行。这个方法运行在Producer的 I/O 线程中，所以这个方法中实现的代码逻辑越简单越好，否则会影响消息的发送速度。

KafkaProducer中不仅可以指定一个拦截器，还可以指定多个拦截器以形成**拦截链**。拦截链会按照interceptor.classes 参数配置的拦截器的顺序来一一执行（配置的时候，各个拦截器之间使用逗号隔开）。

在拦截链中，如果某个拦截器执行失败，那么下一个拦截器会接着从上一个执行成功的拦截器继续执行。

#### 生产者内部架构

Producer端架构如下图：
![](https://raw.githubusercontent.com/rainsbaby/notebook/master/imgs/kafka/kafka_client_architecture.png)

整个生产者客户端由两个线程协调运行，这两个线程分别为主线程和Sender线程（发送线程）。

**ProducerBatch**中可以包含一至多个 ProducerRecord。通俗地说，ProducerRecord 是生产者中创建的消息，而ProducerBatch是指一个消息批次，ProducerRecord会被包含在ProducerBatch中，这样可以使字节的使用更加紧凑，也可以减少网络请求的次数以提升整体的吞吐量。

**InFlightRequests**缓存了已经发出去但还没有收到响应的请求。InFlightRequests还提供了许多管理类的方法，并且通过配置参数还可以限制每个连接（也就是客户端与Node之间的连接）最多缓存的请求数，超过该数值之后就不能再向这个连接发送更多的请求。

InFlightRequests还可以获得leastLoadedNode，即所有Node中负载最小的那一个。选择leastLoadedNode发送请求可以使它能够尽快发出，避免因网络拥塞等异常而影响整体的进度。

**消息发送过程：**

KafkaProducer要将消息追加到指定主题的某个分区所对应的leader副本之前，首先需要知道主题的分区数量，然后经过计算得出（或者直接指定）目标分区，之后KafkaProducer需要知道目标分区的leader副本所在的broker 节点的地址、端口等信息才能建立连接，最终才能将消息发送到 Kafka，在这一过程中所需要的信息都属于元数据信息。

**元数据更新：**
元数据的更新操作是在客户端内部进行的，对客户端的外部使用者不可见。

当需要更新元数据时，会先挑选出leastLoadedNode，然后向这个Node发送MetadataRequest请求来获取具体的元数据信息。这个更新操作是由Sender线程发起的。

#### 配置参数

acks：指定分区中必须要有多少个副本收到这条消息，之后生产者才会认为这条消息是成功写入的。acks=-1（all）时，生产者在消息发送之后，需要等待ISR中的所有副本都成功写入消息之后才能够收到来自服务端的成功响应。在其他配置环境相同的情况下，acks 设置为-1（all）可以达到最强的可靠性。

min.insync.replicas：broker端参数。ISR集合中的最少副本数，默认值是1。只有在acks=all或-1时才有效。

## 消费者

#### 消费组

每一个分区只能被一个消费组中的一个消费者所消费。

消费者与消费组这种模型可以让整体的消费能力具备横向伸缩性，我们可以增加（或减少）消费者的个数来提高（或降低）整体的消费能力。


对于消息中间件而言，一般有两种消息投递模式：点对点（P2P，Point-to-Point）模式和发布/订阅（Pub/Sub）模式。点对点模式是基于队列的，消息生产者发送消息到队列，消息消费者从队列中接收消息。发布/订阅模式在消息的一对多广播时采用。

Kafka中，如果所有的消费者都隶属于同一个消费组，那么所有的消息都会被均衡地投递给每一个消费者，即每条消息只会被一个消费者处理，这就相当于点对点模式的应用。如果所有的消费者都隶属于不同的消费组，那么所有的消息都会被广播给所有的消费者，即每条消息会被所有的消费者处理，这就相当于发布/订阅模式的应用。

消费者不仅可以通过KafkaConsumer.subscribe（）方法订阅主题，还可以直接订阅某些主题的特定分区，在KafkaConsumer中还提供了一个assign（）方法来实现这些功能。


**消息消费：**

Kafka中的消费是基于拉模式的。消息的消费一般有两种模式：推模式和拉模式。

Kafka中的消息消费是一个不断轮询的过程，消费者所要做的就是重复地调用poll（）方法，而poll（）方法返回的是所订阅的主题（分区）上的一组消息。

**消费位移提交：**

消费者使用offset来表示消费到分区中某个消息所在的位置，称为消费位移。

消费位移的作用：消费者在关闭、崩溃或者在遇到再均衡的时候，可以让接替的消费者能够根据存储的消费位移继续进行消费。

在新消费者客户端中，消费位移存储在Kafka内部的主题__consumer_offsets中。这里把将消费位移存储起来（持久化）的动作称为“提交”，消费者在消费完消息之后需要执行消费位移的提交。

在 Kafka 中默认的消费位移的提交方式是**自动提交**，这个由消费者客户端参数enable.auto.commit配置，默认值为 true。

在默认的方式下，消费者每隔5秒会将拉取到的每个分区中最大的消息位移进行提交。自动位移提交的动作是在poll（）方法的逻辑里完成的，在每次真正向服务端发起拉取请求之前会检查是否可以进行位移提交，如果可以，那么就会提交上一次轮询的位移。

自动提交消费位移的方式非常简便，它免去了复杂的位移提交逻辑，让编码更简洁。但随之而来的是**重复消费和消息丢失**的问题。使用本地缓存暂存消息时，就可能出现消息丢失的问题。（主要是消费时间和位移提交时间不是完全一致的，就会导致重复消费或消息丢失）

在Kafka中还提供了**手动位移提交**的方式，这样可以使得开发人员对消费位移的管理控制更加灵活。

手动提交可以细分为同步提交和异步提交。在实际应用中，很少会有每消费一条消息就提交一次消费位移的必要场景。更多时候是按照分区的粒度划分提交位移的界限。

在一般情况下，位移提交失败的情况很少发生，不重试也没有关系，后面的提交也会有成功的。重试会增加代码逻辑的复杂度，不重试会增加重复消费的概率。如果消费者异常退出，那么这个重复消费的问题就很难避免，因为这种情况下无法及时提交消费位移；如果消费者正常退出或发生再均衡的情况，那么可以在退出或再均衡执行之前使用同步提交的方式做最后的把关。

**消费端消息丢失：**

1. 消费端自动提交位移。
2. 消费端手动提交位移。如果是异步提交或批量提交，就可能出现重复消费。



#### 再均衡

再均衡是指分区的所属权从一个消费者转移到另一消费者的行为，它为消费组具备高可用性和伸缩性提供保障，使我们可以既方便又安全地删除消费组内的消费者或往消费组内添加消费者。

再均衡监听器 ConsumerRebalanceListener，用来设定发生再均衡动作前后的一些准备或收尾的动作，如提交消费位移等。